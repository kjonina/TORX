{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "addf9a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Karina\\miniconda3\\lib\\site-packages\\requests\\__init__.py:109: RequestsDependencyWarning: urllib3 (2.2.2) or chardet (3.0.4)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import html\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "189fce91",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = ['2021','2022', '2023',  '2024']\n",
    "races = ['TOR330' , 'TOR450' ]\n",
    "delay_seconds = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116bc7a0",
   "metadata": {},
   "source": [
    "## Scraping TORX Data from the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c87eb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for race in races:\n",
    "#     for year in years:\n",
    "#         # URL of the JSON file\n",
    "#         url = f'https://100x100trail.com/json/{race}{year}.json'\n",
    "\n",
    "#         # Send a GET request to fetch the JSON data\n",
    "#         response = requests.get(url)\n",
    "\n",
    "#         # Check if the request was successful (status code 200)\n",
    "#         if response.status_code == 200:\n",
    "#             # Parse the JSON data\n",
    "#             data = response.json()\n",
    "\n",
    "#             # Optionally, save the data to a JSON file\n",
    "#             with open(f'{race} Data/100x100trail/JSON/{race}_{year}.json', 'w') as f:\n",
    "#                 json.dump(data, f, indent=4)\n",
    "\n",
    "#             print(f\"Data saved to '{race}_{year}.json'\")\n",
    "#         else:\n",
    "#             print(f\"Failed to retrieve data. Status code: {response.status_code}\")\n",
    "\n",
    "#         time.sleep(delay_seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525dd60f",
   "metadata": {},
   "source": [
    "## Extracting Data from JSON data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a347de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a list to hold the rows for the DataFrame\n",
    "rows = []\n",
    "aid_station_list = []\n",
    "\n",
    "# Function to parse each entry\n",
    "def parse_data(entries, race, year):\n",
    "    n = 0\n",
    "    for entry in entries:\n",
    "        attributes = entry[\"data\"][\"attributes\"]\n",
    "        name = html.unescape(attributes[\"name\"]).title()\n",
    "        team = attributes[\"team\"]\n",
    "        bib_number = attributes[\"pettorale\"]\n",
    "        sex = attributes[\"sesso\"]\n",
    "        nationality = attributes[\"nazionalita\"]\n",
    "        category = attributes[\"categoria\"]\n",
    "        finisher_status = attributes[\"finisher\"]\n",
    "        \n",
    "        race = f'{race}'\n",
    "        year = f'{year}'\n",
    "        \n",
    "        #\"Bib\", \"Name\", \"Team\", \"Sex\",  'Nationality','Race', 'Status' \n",
    "        all_info = [ bib_number, name, team, sex, nationality, race,year, finisher_status ]\n",
    "        # Append the row to the list\n",
    "        rows.append(all_info)\n",
    "\n",
    "        # Extracting times and places\n",
    "        events = entry[\"data\"][\"relationships\"][\"events\"][\"data\"]\n",
    "\n",
    "        for event in events:\n",
    "            place = event['title']\n",
    "            time = event['start_date']\n",
    "\n",
    "            aid_station_info = [name, bib_number,  sex, nationality,race,year,\n",
    "                                category, place, time, finisher_status]\n",
    "        \n",
    "#             print(aid_station_info)\n",
    "            aid_station_list.append(aid_station_info)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "323745b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove special characters\n",
    "def normalize_name(name):\n",
    "    # Normalize to remove accents and special characters\n",
    "    name = unicodedata.normalize('NFD', name)\n",
    "    # Encode to ASCII and ignore errors, then decode back to string\n",
    "    name = name.encode('ascii', 'ignore').decode('utf-8')\n",
    "    return name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6367b9b",
   "metadata": {},
   "source": [
    "## Looping through scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a1effca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to f'TOR330_2021.xlsx'\n",
      "******************************\n",
      "Data saved to f'TOR330_2022.xlsx'\n",
      "******************************\n",
      "Data saved to f'TOR330_2023.xlsx'\n",
      "******************************\n",
      "Data saved to f'TOR330_2024.xlsx'\n",
      "******************************\n",
      "Data saved to f'TOR450_2021.xlsx'\n",
      "******************************\n",
      "Data saved to f'TOR450_2022.xlsx'\n",
      "******************************\n",
      "Data saved to f'TOR450_2023.xlsx'\n",
      "******************************\n",
      "Data saved to f'TOR450_2024.xlsx'\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "TORX_df = {}\n",
    "aid_station_TORX_df = {}\n",
    "\n",
    "\n",
    "for race in races:\n",
    "    for year in years:\n",
    "        rows=[]\n",
    "        aid_station_list = []\n",
    "\n",
    "        # Load the JSON data from a file\n",
    "        with open(f'{race} Data/100x100trail/JSON/{race}_{year}.json', 'r') as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "            # parse data\n",
    "            parse_data(data, race, year)\n",
    "\n",
    "            # Create a DataFrame\n",
    "            df = pd.DataFrame(rows, columns=[\n",
    "        #        bib_number, name, team, gender, nationality, race, finisher_status\n",
    "               \"Bib\", \"Name\", \"Team\", \"Sex\",  'Nationality','Race','Year',  'Status' ])\n",
    "            \n",
    "#             print(df.info())\n",
    "\n",
    "            # Create a DataFrame\n",
    "            aid_station_df = pd.DataFrame(aid_station_list, columns=[\n",
    "        #    name, bib_number,  sex, nationality,race,year,\n",
    "#           category, place, time, finisher_status\n",
    "               \"Name\", \"Bib\", 'Sex', 'Nationality','Race', 'Year',\n",
    "                \"Category\",  'Place', 'Time', 'Status' ])    \n",
    "\n",
    "            df['Name'] = df['Name'].str.strip()\n",
    "            df['Name'] = df['Name'].str.replace(',', '')\n",
    "            df['Name'] = df['Name'].str.replace('\\'', ' ')\n",
    "\n",
    "            df['Name'] = df['Name'].apply(normalize_name)\n",
    "            aid_station_df['Name'] = aid_station_df['Name'].apply(normalize_name)\n",
    "            \n",
    "            df.to_excel(f'{race} Data/100x100trail/{race}_{year}.xlsx' , index = False)\n",
    "            aid_station_df.to_excel(f'{race} Data/100x100trail/aid_station_{race}_{year}.xlsx' , index = False)\n",
    "            \n",
    "            TORX_df[f'{race}_{year}'] = df\n",
    "            aid_station_TORX_df[f'{race}_{year}'] = aid_station_df\n",
    "                \n",
    "            print(f\"Data saved to f'{race}_{year}.xlsx'\")\n",
    "\n",
    "            print('*'*30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b54d898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "639d6ad0",
   "metadata": {},
   "source": [
    "## Making sense of abbreviated nationalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd46240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TORX_df[f'{race}_{year}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9629070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a set to store unique nationalities\n",
    "unique_nationalities = set()\n",
    "\n",
    "for race in races:\n",
    "    for year in years:\n",
    "        # Get unique nationalities for the year and update the set\n",
    "        df_nationalities = TORX_df[f'{race}_{year}']['Nationality'].unique()\n",
    "        unique_nationalities.update(df_nationalities)\n",
    "\n",
    "    # Convert the set back to a sorted list\n",
    "unique_nationalities_list = sorted(unique_nationalities)\n",
    "\n",
    "print(len(unique_nationalities_list))\n",
    "print(unique_nationalities_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a313bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for updated nationality abbreviations\n",
    "country_mapping = {\n",
    "    'AD': 'Andorra', 'AE': 'United Arab Emirates', 'AI': 'Anguilla', 'AQ': 'Antarctica',\n",
    "    'AR': 'Argentina', 'AT': 'Austria', 'AU': 'Australia', 'BE': 'Belgium', 'BG': 'Bulgaria',\n",
    "    'BN': 'Brunei', 'BO': 'Bolivia', 'BR': 'Brazil', 'CA': 'Canada', 'CH': 'Switzerland',\n",
    "    'CL': 'Chile', 'CN': 'China', 'CO': 'Colombia', 'CR': 'Costa Rica', 'CY': 'Cyprus',\n",
    "    'CZ': 'Czech Republic', 'DE': 'Germany', 'DK': 'Denmark', 'EC': 'Ecuador', 'EE': 'Estonia',\n",
    "    'ES': 'Spain', 'FI': 'Finland', 'FR': 'France', 'GB': 'United Kingdom', 'GF': 'French Guiana',\n",
    "    'GP': 'Guadeloupe', 'GR': 'Greece', 'GT': 'Guatemala', 'HK': 'Hong Kong', 'HR': 'Croatia',\n",
    "    'HU': 'Hungary', 'ID': 'Indonesia', 'IE': 'Ireland', 'IL': 'Israel', 'IM': 'Isle of Man',\n",
    "    'IR': 'Iran', 'IS': 'Iceland', 'IT': 'Italy', 'JO': 'Jordan', 'JP': 'Japan', 'KR': 'South Korea',\n",
    "    'KZ': 'Kazakhstan', 'LT': 'Lithuania', 'LV': 'Latvia', 'MA': 'Morocco', 'MC': 'Monaco',\n",
    "    'ME': 'Montenegro', 'MO': 'Macau', 'MQ': 'Martinique', 'MT': 'Malta', 'MU': 'Mauritius',\n",
    "    'MX': 'Mexico', 'MY': 'Malaysia', 'NC': 'New Caledonia', 'NL': 'Netherlands', 'NO': 'Norway',\n",
    "    'NZ': 'New Zealand', 'PE': 'Peru', 'PF': 'French Polynesia', 'PH': 'Philippines', 'PL': 'Poland',\n",
    "    'PT': 'Portugal', 'QA': 'Qatar', 'RE': 'Réunion', 'RO': 'Romania', 'RS': 'Serbia', 'RU': 'Russia',\n",
    "    'SA': 'Saudi Arabia', 'SE': 'Sweden', 'SG': 'Singapore', 'SI': 'Slovenia', 'SK': 'Slovakia',\n",
    "    'SM': 'San Marino', 'TH': 'Thailand', 'TR': 'Turkey', 'TW': 'Taiwan', 'UA': 'Ukraine',\n",
    "    'US': 'United States', 'UY': 'Uruguay', 'VE': 'Venezuela', 'VN': 'Vietnam', 'ZA': 'South Africa'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477e8f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionary to DataFrame\n",
    "country_df = pd.DataFrame(list(country_mapping.items()), columns=['Nationality', 'Nationality Name'])\n",
    "\n",
    "print(country_df)\n",
    "\n",
    "country_df .to_excel(f'Database Data/TORX_100x100trail_nationality_table.xlsx', sheet_name = 'Nationality Code', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718cea28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3a8921",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
